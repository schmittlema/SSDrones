{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, input_sizes, output_size):\n",
    "        \"\"\"Cretes a neural network layer.\"\"\"\n",
    "        if type(input_sizes) != list:\n",
    "            input_sizes = [input_sizes]\n",
    "        \n",
    "        self.input_sizes = input_sizes\n",
    "        self.output_size = output_size\n",
    "                \n",
    "        self.Ws = []\n",
    "        for input_size in input_sizes:\n",
    "            tensor_W = tf.random_uniform((input_size, output_size),\n",
    "                                         -1.0 / math.sqrt(input_size),\n",
    "                                         1.0 / math.sqrt(input_size))\n",
    "            self.Ws.append(tf.Variable(tensor_W))\n",
    "\n",
    "        tensor_b = tf.zeros((output_size,))\n",
    "        self.b = tf.Variable(tensor_b)\n",
    "            \n",
    "    def __call__(self, xs):\n",
    "        if type(xs) != list:\n",
    "            xs = [xs]\n",
    "        assert len(xs) == len(self.Ws), \\\n",
    "                \"Expected %d input vectors, got %d\" % (len(self.Ws), len(x))\n",
    "        return sum([tf.matmul(x, W) for x, W in zip(xs, self.Ws)]) + self.b\n",
    "\n",
    "        \n",
    "class MLP(object):\n",
    "    def __init__(self, input_sizes, hiddens, nonlinearities,brainName):\n",
    "        self.input_sizes = input_sizes\n",
    "        self.hiddens = hiddens\n",
    "        self.input_nonlinearity, self.layer_nonlinearities = nonlinearities[0], nonlinearities[1:]\n",
    "        self.count = 0\n",
    "        self.bN = brainName\n",
    "        assert len(hiddens) == len(nonlinearities), \\\n",
    "                \"Number of hiddens must be equal to number of nonlinearities\"\n",
    "        \n",
    "        self.input_layer = Layer(input_sizes, hiddens[0])\n",
    "        self.layers = [Layer(h_from, h_to) for h_from, h_to in zip(hiddens[:-1], hiddens[1:])]\n",
    "\n",
    "    def __call__(self, xs):\n",
    "        self.count = self.count +1 \n",
    "        if(self.count == 10):\n",
    "            self.count = 0\n",
    "        self.saveNetwork()\n",
    "        if type(xs) != list:\n",
    "            xs = [xs]\n",
    "        hidden = self.input_nonlinearity(self.input_layer(xs))\n",
    "        for layer, nonlinearity in zip(self.layers, self.layer_nonlinearities):\n",
    "            hidden = nonlinearity(layer(hidden))\n",
    "        return hidden\n",
    "    \n",
    "    def saveNetwork(self):\n",
    "        path = \"../saved_brains/\"\n",
    "        name = \"Brain:_\"# + self.bN\n",
    "        name = os.path.join(path,name)\n",
    "        wtf = open(name,\"w\")\n",
    "        #wtf.write(self.input_layer)\n",
    "        wtf.write(\"hi\")\n",
    "        wtf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test code\n",
    "#mlp = MLP(5,[5,5,5],[5,5,5],\"test\")\n",
    "#for i in range(0,10):\n",
    " #   mlp(5.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
